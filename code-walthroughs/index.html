<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Code Walkthroughs - Machine Learning for Tagging Graphic Designs</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Code Walkthroughs";
    var mkdocs_page_input_path = "code-walthroughs.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Machine Learning for Tagging Graphic Designs</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../setup/">Setup Instructions</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../tands/">Tools and Services</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../system/">System Overview</a>
                    </li>
                </ul>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Code Walkthroughs</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#code-walkthrough-training">Code Walkthrough: Training</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#import-required-libraries-set-role-and-session">Import required libraries. Set role and session.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#set-data-channels">Set Data Channels.</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#get-training-image">Get Training Image</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#create-estimator">Create Estimator</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#run-training">Run Training</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#code-walkthrough-hyperparameter-tuning">Code Walkthrough: Hyperparameter Tuning</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#set-initial-hyperparameters">Set Initial Hyperparameters</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#set-hyperparameter-ranges-and-create-tuner">Set Hyperparameter Ranges and Create Tuner</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#run-tuning">Run Tuning</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#tuner-output">Tuner Output</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#code-walkthrough-creating-datasets">Code Walkthrough: Creating Datasets</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#downloading-the-images">Downloading the Images</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#generating-the-dataset">Generating the Dataset</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../resources/">Additional Resources</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Machine Learning for Tagging Graphic Designs</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Code Walkthroughs</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="code-walkthroughs">Code Walkthroughs</h1>
<p>Lets look at how the code works.</p>
<hr />
<h2 id="code-walkthrough-training">Code Walkthrough: Training</h2>
<p>This walkthrough takes you through the code used to train a single model. We will look at the files in our Jupyter Notebook called <code>334-label/resize-96/train.ipynb</code> and <code>50-label/resize-96/train.ipynb</code>. </p>
<p><strong>Note:</strong> These two files use different datasets for training, however the structure of the code is exactly the same.</p>
<p>The training code follows these steps:</p>
<h3 id="import-required-libraries-set-role-and-session">Import required libraries. Set role and session.</h3>
<p>First we import some libraries that we need to use to create the training job.</p>
<pre><code>import sagemaker
from sagemaker import get_execution_role
from sagemaker.amazon.amazon_estimator import image_uris
from sagemaker.image_uris import retrieve, config_for_framework

role = get_execution_role()
sess = sagemaker.Session()
</code></pre>
<h3 id="set-data-channels">Set Data Channels.</h3>
<p>Next we specify the training inputs. In other words we tell the training job where to get our training and validation data as well as where it should send its output.</p>
<p>First we format the S3 paths to the training and validation data. We also format the S3 path that will be used to store output. </p>
<pre><code>bucket = 'sagemaker-multi-label-data'
prefix = 'ic-multi-label'

training = 's3://{}/{}/training/'.format(bucket, prefix)
validation = 's3://{}/{}/validation/'.format(bucket, prefix)
output = 's3://{}/{}/output'.format(bucket, prefix)
</code></pre>
<p>Next create create the training inputs and set the data channels. In other words we are telling the training job a little bit about the data it will use for training.</p>
<p>For example we have to set <code>content_type='application/x-recordio'</code> because our dataset uses the RecordIO data format.</p>
<pre><code>train_data = sagemaker.inputs.TrainingInput(
    training, 
    distribution='FullyReplicated', 
    content_type='application/x-recordio', 
    s3_data_type='S3Prefix'
)

validation_data = sagemaker.inputs.TrainingInput(
    validation, 
    distribution='FullyReplicated', 
    content_type='application/x-recordio', 
    s3_data_type='S3Prefix'
)

data_channels = {'train': train_data, 'validation': validation_data}
</code></pre>
<h3 id="get-training-image">Get Training Image</h3>
<p>We also need to provide a machine learning algorithm to our training job this is called a training image. We use SageMakers built-in Image Classification algorithm for our training image.</p>
<pre><code>training_image = retrieve('image-classification', sess.boto_region_name)
</code></pre>
<h3 id="create-estimator">Create Estimator</h3>
<p>Next, we create an estimator object. Here we chose what type of instance the training job will use and how instances we want to run in parallel.</p>
<pre><code>multilabel_ic = sagemaker.estimator.Estimator(
    training_image,
    role, 
    instance_count = 1, 
    instance_type = 'ml.p3.2xlarge',
    output_path = output,
    sagemaker_session = sess
    )
</code></pre>
<p>Then we set the estimators hyper-parameters. The values we chose for these hyper-parameters can significantly effect our models accuracy. We may want to adjust them and re-train our models to see if we can get better accuracy.</p>
<p>Its important to make sure the <code>num_classes</code> is set to the number of classes in our dataset or else the training will fail. Similarly <code>num_training_samples</code> must be set to the number of samples in the training data, or else the training will fail.</p>
<p>For more information on hyper-parameters read <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html">Image Classification Hyperparameters</a>.</p>
<pre><code>multilabel_ic.set_hyperparameters(
    num_classes = 334,
    num_training_samples = 116945,
    augmentation_type = 'crop_color_transform',
    epochs=5,
    image_shape = "3,96,96",  
    learning_rate = 0.001,
    mini_batch_size = 256,
    multi_label = 1,
    use_weighted_loss = 1,
    optimizer = 'adam'
    )
</code></pre>
<h3 id="run-training">Run Training</h3>
<p>Finally we can begin the training. We specify our data channels as the inputs for training then run the training job and wait for it to finish.</p>
<pre><code>multilabel_ic.fit(inputs = data_channels, logs = True)
</code></pre>
<hr />
<h2 id="code-walkthrough-hyperparameter-tuning">Code Walkthrough: Hyperparameter Tuning</h2>
<p>This walkthrough takes you through the code used to automatically tune a models hyperparameters. We will look at the files in our Jupyter Notebook called 334-label/resize-96/tune.ipynb and 50-label/resize-96/tune.ipynb. </p>
<p>Creating a hyperparameter tuning job is very similar to creating a normal training job. One difference is instead of hard-coding the values of hyperparameters, we set ranges of hyper-parameter values. The hyperparameter tuning job will automatically train and re-train models adjusting the hyperparameters within the ranges we set.</p>
<h3 id="set-initial-hyperparameters">Set Initial Hyperparameters</h3>
<p>We provide the hyperparameters that cant be changed</p>
<pre><code>multilabel_ic.set_hyperparameters(
    num_classes=334,
    num_training_samples=116945,
    augmentation_type = 'crop_color_transform',
    epochs=5,
    image_shape = "3,96,96",
    multi_label=1,
    use_weighted_loss=1
    )
</code></pre>
<h3 id="set-hyperparameter-ranges-and-create-tuner">Set Hyperparameter Ranges and Create Tuner</h3>
<p>There are 3 types of parameters:</p>
<ol>
<li>Continuous: all values in the specified range can be used.</li>
<li>Integer: all integers in specified range can be used.</li>
<li>Categorical: any of the values in a list can be used.</li>
</ol>
<p>Here we set the parameter ranges and create the tuner object. </p>
<p>The <code>max_jobs</code> property of the tuner tells the tuning job how many different models to train with different parameters.</p>
<p>The <code>max_parallel_jobs</code> property of the tuner tells the tuning job how many training jobs to run at once. </p>
<pre><code>tuning_job_name = "imageclassif-job-{}".format(strftime("%d-%H-%M-%S", gmtime()))

hyperparameter_ranges = {
    'learning_rate': ContinuousParameter(0.0001, 0.05),
    'mini_batch_size': IntegerParameter(126, 256),
    'optimizer': CategoricalParameter(['sgd', 'adam', 'rmsprop', 'nag'])}

objective_metric_name = 'validation:accuracy'

tuner = HyperparameterTuner(
    multilabel_ic,
    objective_metric_name,
    hyperparameter_ranges,
    objective_type='Maximize',
    max_jobs=2,
    max_parallel_jobs=1)
</code></pre>
<h3 id="run-tuning">Run Tuning</h3>
<p>Now we run the tuner and wait for it to finish.</p>
<pre><code>tuner.fit(data_channels, job_name=tuning_job_name, include_cls_metadata=False)
tuner.wait()
</code></pre>
<h3 id="tuner-output">Tuner Output</h3>
<p>The models created by the tuner can be viewed and deployed from the SageMaker dashboard. The hyperparameters used for each training job can also be viewed through the SageMaker dashboard.</p>
<hr />
<h2 id="code-walkthrough-creating-datasets">Code Walkthrough: Creating Datasets</h2>
<p>This walkthrough will take you through the process of creating a new dataset.</p>
<h3 id="requirements">Requirements</h3>
<ul>
<li>Local machine with at least 250 GB of free space.</li>
<li>AWS credentials (aws_access_key_id and aws_secret_access_key)</li>
<li>The file s3-paths.txt</li>
<li>MXNet installed on local machine</li>
<li>train.lst and val.lst files.</li>
</ul>
<h3 id="downloading-the-images">Downloading the Images</h3>
<p>The first step in creating the dataset is downloading all of the images. I did this with the following files and python script:</p>
<p><strong>Note:</strong> aws_access_key_id and aws_secret_access_key will be omitted for privacy.</p>
<p>Files: <code>s3-paths.txt</code> contains all of the images S3 locations.</p>
<p>The script I used to download the images from S3 takes the following steps:</p>
<ol>
<li>Connect to Amazon S3 with Boto3</li>
<li>Read each image location from s3-paths.txt</li>
<li>Download the image saving it in the <code>images/</code> directory.</li>
<li>Logging which images were downloaded successfully and which images were not.</li>
</ol>
<p>Downloading images script: </p>
<pre><code>import boto3
import botocore
from botocore.retries import bucket

s3_paths = open('s3-paths.txt', 'r')

error_logs = open('logs.txt', 'w+')

no_download = open('no-download.txt', 'w+')

downloaded = open('downloaded.txt', 'w+')

session = boto3.Session(
    aws_access_key_id=,
    aws_secret_access_key=
)
s3 = session.resource('s3')

bucket = 'pixelscrapper-user-content'

for path in s3_paths:
    local = 'images/' + path.split('/')[-1].split('\n')[0]
    try:
        s3.Bucket(bucket).download_file(path.split('\n')[0], local)
        downloaded.write(path)
    except botocore.exceptions.ClientError as error:
        error_logs.write(str(error) + path)
        no_download.write(path)
</code></pre>
<p>After this script completes we will have all of the images stored in a directory called <code>images</code>. </p>
<h3 id="generating-the-dataset">Generating the Dataset</h3>
<p>After downloading the images, we need to process them to create our dataset.</p>
<p>First we get the path of the im2rec.py tool by running the following:</p>
<pre><code>import mxnet
path = mxnet.test_utils.get_im2rec_path()
print(path)
</code></pre>
<p>Copy the printed path and save it somewhere. We will use this path later on to run the im2rec tool.</p>
<p>At this point we should have the following:</p>
<ul>
<li>A file called: <code>train.lst</code> containing the label data and local paths to training images.</li>
<li>A file called: <code>val.lst</code> containing the label data and local paths to validation images.</li>
<li>The path to <code>im2rec.py</code> </li>
<li><code>images</code> directory containing all downloaded images</li>
</ul>
<p>The following shows the output of running <code>im2rec.py -h</code>. You can see there are many options and arguments, so lets narrow down the most important ones. </p>
<pre><code>usage: im2rec.py [-h] [--list] [--exts EXTS [EXTS ...]] [--chunks CHUNKS]
                [--train-ratio TRAIN_RATIO] [--test-ratio TEST_RATIO]
                [--recursive] [--no-shuffle] [--pass-through]
                [--resize RESIZE] [--center-crop] [--quality QUALITY]
                [--num-thread NUM_THREAD] [--color {-1,0,1}]
                [--encoding {.jpg,.png}] [--pack-label]
                prefix root

Create an image list or make a record database by reading from an image list

positional arguments:
prefix                prefix of input/output lst and rec files.
root                  path to folder containing images.

optional arguments:
-h, --help            show this help message and exit

Options for creating image lists:
--list                If this is set im2rec will create image list(s) by
                        traversing root folder and output to &lt;prefix&gt;.lst.
                        Otherwise im2rec will read &lt;prefix&gt;.lst and create a
                        database at &lt;prefix&gt;.rec (default: False)
--exts EXTS [EXTS ...]
                        list of acceptable image extensions. (default:
                        ['.jpeg', '.jpg', '.png'])
--chunks CHUNKS       number of chunks. (default: 1)
--train-ratio TRAIN_RATIO
                        Ratio of images to use for training. (default: 1.0)
--test-ratio TEST_RATIO
                        Ratio of images to use for testing. (default: 0)
--recursive           If true recursively walk through subdirs and assign an
                        unique label to images in each folder. Otherwise only
                        include images in the root folder and give them label
                        1. (default: False)
--no-shuffle          If this is passed, im2rec will not randomize the image
                        order in &lt;prefix&gt;.lst (default: True)

Options for creating database:
--pass-through        whether to skip transformation and save image as is
                        (default: False)
--resize RESIZE       resize the shorter edge of image to the newsize,
                        original images will be packed by default. (default:
                        0)
--center-crop         specify whether to crop the center image to make it
                        rectangular. (default: False)
--quality QUALITY     JPEG quality for encoding, 1-100; or PNG compression
                        for encoding, 1-9 (default: 95)
--num-thread NUM_THREAD
                        number of thread to use for encoding. order of images
                        will be different from the input list if &gt;1. the input
                        list will be modified to match the resulting order.
                        (default: 1)
--color {-1,0,1}      specify the color mode of the loaded image. 1: Loads a
                        color image. Any transparency of image will be
                        neglected. It is the default flag. 0: Loads image in
                        grayscale mode. -1:Loads image as such including alpha
                        channel. (default: 1)
--encoding {.jpg,.png}
                        specify the encoding of the images. (default: .jpg)
--pack-label          Whether to also pack multi dimensional label in the
                        record file (default: False)
</code></pre>
<p>We already have the training and validation list files, so we are not interested in using im2rec to create those. We are primarily concerned with using im2rec to create the databases.</p>
<p>The most important arguments for creating our dataset using im2rec are:</p>
<pre><code>--resize RESIZE       resize the shorter edge of image to the newsize,
                        original images will be packed by default. (default:
                        0)
--num-thread NUM_THREAD
                        number of thread to use for encoding. order of images
                        will be different from the input list if &gt;1. the input
                        list will be modified to match the resulting order.
                        (default: 1)

--pack-label          Whether to also pack multi dimensional label in the
                        record file (default: False)
</code></pre>
<p><strong>Important:</strong> you can change the resize value and number of threads in the following commands if you want. These are just examples.</p>
<p>Create the training record by running:</p>
<pre><code>$ path/to/im2rec.py --resize 256 --num-thread 4 --pack-label train.lst images
</code></pre>
<p>This will generate the files <code>train.rec</code> and <code>train.idx</code>.</p>
<p>Next, create the validation record by running:</p>
<pre><code>$ path/to/im2rec.py --resize 256 --num-thread 4 --pack-label val.lst images
</code></pre>
<p>This will generate the files <code>val.rec</code> and <code>val.idx</code>.</p>
<p><code>train.rec</code> and <code>val.rec</code> are now ready to be uploaded to Amazon S3 where they can be used as training inputs.</p>
<hr />
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../resources/" class="btn btn-neutral float-right" title="Additional Resources">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../system/" class="btn btn-neutral" title="System Overview"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../system/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../resources/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
